---
layout: post
title: My basic understanding of HMC
date: 2023-09-17 19:32:00-0800
description: Maybe appropriate for physics-background people. Some of examples are imagined by myself and could be wrong.
categories: theories
tags: sampling
giscus_comments: true
related_posts: false
toc:
  sidebar: left
---

The Hamitonian Monte Carlo (HMC) and its variants are almost the best sampling algorithms now, as long as you can get access to the gradient. I've learnt it several years ago, but soon forgot. Now I try again, to understand it in a physicist way -- though i'm not a physicist.

## Traditional MCMC

Suppose we want to get the distribution $$V(q)$$ of an variable $$q$$ (let's name it in Hamitonian way), one thing we can learn from the statistical physics is that at equilibrium state, a physical system with potential $$U(q)$$ converges at $$p(q)\propto \exp^{-U(q)}$$ (Assume kinetic energy is much less than the potential energy in this system). Then one can easily figure out, the distribution $$V(q)$$ is equivalent to the particle distribution in a physical system with potential $$- \log V(q)$$ in the equilibrium state. Suppose this state have many particles -- their distribution will show us our target distribution.

-- But how do we get these particles? One solution is  we need to sample all over the space. How do we do the sampling to assume every new state we sampled follows the desired distribution? `detailed balance' can help on this. The detailed balance tells us, in the equilibrium, the transition probability from $$q_0$$ to $$q_1$$ and its inverse follows:
$$
\begin{equation}
  p_t(q_0 \rightarrow q_1) p(q_0) = p_t(q_1 \rightarrow q_0) p(q_1)
\label{eqn:detbal}
\end{equation}
$$
where $$p_t$$ represents the transition probability. Its meaning is precise and clear: at any time, the number of transition events from $$q_1$$ to $$q_0$$ should be the same of $$q_0$$ to $$q_1$$, thus the total distribution holds. After knowing this, we can see the sampling process as a chain of transitions: a particle in this system will transit all the time, and the time evolution can be viewed as ensembles. It's interesting that in statistical physics we use ensemble average to substitude the time average, while now we do the opposite. Now one can create a transition probability:
$$
\begin{equation}
  p_t(q_0 \rightarrow q_1) = \left\{
\begin{aligned}
&1   &p(q_0)<p(q_1) \\
&\frac{p(q_1)}{p(q_0)}\ \  &p(q_0)>p(q_1)
\end{aligned}
\right.
\label{eqn:tranprob}
\end{equation}
$$
It's not hard to check this equation is consistent with equation \eqref{eqn:detbal}.

Then one can imagine in a physical system, a particle $$q$$ will go through a bunch of states:
$$
\begin{equation}
  {\rm State}_0 \rightarrow {\rm State}_1 \rightarrow {\rm State}_2\rightarrow ... \rightarrow {\rm State}_n
\label{eqn:chain}
\end{equation}
$$
And the distribution of all these $$n$$ states follows the $$V(q)$$.

Imagine we have a two-level system, with only two possible states, let's do this process for $$n$$ times: suppose $$q_0$$ has lower potential energy and we start from it. Then assume process $$q_0 \rightarrow q_1$$ is tried $$x$$ times, the backward process must happen $$x*p(q_1)/p(q_0)$$ times. So among all the samples, we have $$x*p(q_1)/p(q_0)$$ $$q_1$$, and $$x$$ $$q_0$$, and you can see it perfectly recovers the distribution.

-- But in real problem we have infinite possible states! Does this relation still holds? Yes. Suppose we run a long chain as in \eqnref{eqn:chain}, and it has come to a steady state, thus the distribution of particles $$\pi(q)$$ won't change overtime. Let's cut the total chain into two parts: the first part is $${\rm State}_0,{\rm State}_2,{\rm State}_4,...$$ and the second part is $${\rm State}_1,{\rm State}_3,{\rm State}_5,...$$ and since it is long enough, we can imagine half of the total samples should also be in steady state, thus, the distribution $$\pi_1(q)$$ and $$\pi_2(q)$$ for both part should be the same, same as the total distribution, and more interestingly, the second part can be view as the acceptance result of part 1. So we can interpret these two parts as: first we have a sample (group 1), them we let all particles in this sample to do a transition (no matter successful or not), and we get the group 2.

Then we just randomly choose a random position $$q_1$$, in the sample, they appears $$n_1 = n*\pi(q_1)$$ times. Then total successful transition from $$q_1$$ to all other places is:

$$
\begin{equation}
  n_{1,\rm out} =  \int n*\pi(q_1)Q(q\vert q_1)p(q_1\rightarrow q) \ dq
\end{equation}
$$

Where $$Q(q_1\vert q)$$ is the probability of proposing $$q_1$$ as the next destination. Samely, successful transitions from all other places to $$q_1$$ is:
$$
\begin{equation}
  n_{1,\rm in} =  \int n*\pi(q)Q(q_1\vert q)p(q\rightarrow q_1)\ dq
\end{equation}
$$

Then as we talked just now, a steady state means $$n_{1,\rm out} = n_{1,\rm in}$$ at each location, thus we have:

$$
\begin{equation}
  \int n*\pi(q_1)Q(q\vert q_1)p(q_1\rightarrow q) \ dq = \int n*\pi(q)Q(q_1\vert q)p(q\rightarrow q_1)\ dq
\end{equation}
$$

Differetiate both sides yield:

$$
\begin{equation}
   \pi(q_1)Q(q\vert q_1)p(q_1\rightarrow q) = \pi(q)Q(q_1\vert q)p(q\rightarrow q_1)
\end{equation}
$$

Then we can see that if we just use a location proposal function $$Q$$ that satifies $$Q(q\vert q_1)=Q(q_1\vert q)$$, then the above equation comes to:

$$
\begin{equation}
   \pi(q_1)p(q_1\rightarrow q) = \pi(q)p(q\rightarrow q_1)
\end{equation}
$$

Applied the equation \eqnref{eqn:tranprob}, we can get:

$$
\begin{equation}
   \pi(q_1)/p(q_1) = \pi(q)/p(q)
\end{equation}
$$

Since integration of $$\pi(q)$$ and $$p(q)$$ are all 1, one can find that $$\pi(q) = p(q)$$ must hold. We've already know the desired distribution can be gained once the detailed balance is achieved, and we just proved that if we construct this chain follows the detailed balance rule, we will get the target distribution. I've forgotten how do we prove the equivalence between equilibrium state and detailed balance, but I guess it should be similar.

So far so good? But the traditional MCMC have some problem, and I'll talk about how do we deal with the problem with Hamitonian Monte-Carlo.
